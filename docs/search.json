[
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "In the field of AI Alignment, ‘Interpretability’ is the study of understanding neural networks; what they learn from training data and how they are forming their predictions.\nThe first step in interpretability is typically to understand the features a neuron is learning from. There would be no mystery if neurons corresponded to verifiable input features. For example, if a neuron fires on dog tails, or on Korean poetry. Since neural networks incorporate non-linearities, this is not always the case, and we will see how small a fraction of features we are able to extract in relation to the number of neurons in a network. This phenonemon is known as ‘superposition’.\nLet’s consider the canonical MNIST machine learning example. MNIST is a dataset of 60,000 training images of handwritten digits, 0-9 (10 classes). Each image is 28x28 pixels, so 784 pixels in total.\nIn the most interpretable scenario, each neuron in a neural network would correspond to a specific feature of the input, for example:\n\nloops (for 0, 6, 8, 9 etc)\nstraight lines (1, 4, 7)\ncurves (2, 3, 5)\n\nIn the image below, we see the original handwritten digits, and a heatmap showing the regions of the digits that had high predictive value. Notice for example how the criss-cross of the eight, which is unique to the digit, is highlighted with blue (strong correlation), and similarly, the curve of the five.\n\nIn practice, however, neural nets don’t learn clean, one-to-one mappings between neurond and features.\n\n1.0.1 Why does superposition occur?\n\nEfficiency: networks often have fewer parameters than the number of features they need to represent. In the case of large language models, for example, this means networks do not have to extend to every last possible feature of language found in vast text corpora.\nGeneralization: overlapping representations help generalize to new data.\nNon-linearity: this allows for complex, overlapping representations. For example, the combination of features in different neurons, sushi in one and recipie quantities in another, can help formulate accurate predictions.\n\nWe will see in this short course that neural networks often represent more features than they have dimensions, and mix different, unrelated concepts in single neurons. For example, a neuron in a language model could fire in response to inputs as varied as code in Haskell, Spanish poetry and vehicle descriptions.\nLet’s move on to the next chapter to examine this fascinating field and look closely at what we can see neural networks are doing, and what we yet cannot.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "superposition.html",
    "href": "superposition.html",
    "title": "2  Initial explorations",
    "section": "",
    "text": "!pip install torchviz torch transformers torchvision\n\nLet’s make a sinple neural network of two layers and a fully-connected layer.\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 128)  # 784 input features\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 10)\n\n    def forward(self, x):\n        x = x.view(x.size(0), -1)  # Flatten the input\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\n# Create the model and move it to GPU\nmodel = SimpleNet().to(device)\n\nThere are various ways of building a more intuitive understanding of the model we just made. The simplest is to print its architecture:\n\nprint(model)\n\nSimpleNet(\n  (fc1): Linear(in_features=784, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=10, bias=True)\n)\n\n\nWe can also use the torchviz library to create a helpful visualization:\n\nfrom torchviz import make_dot\n\n# Same size as input data\ndummy_input = torch.randn(1, 28, 28).cuda()\n\ngraph = make_dot(model(dummy_input), params=dict(model.named_parameters()))\ngraph.render(\"Model\", format=\"png\", cleanup=True)\n\n'Model.png'\n\n\n\nfrom IPython.display import Image, display\n\n# Display the image in the notebook\nimage_path = \"Model.png\"\ndisplay(Image(filename=image_path))\n\n\n\n\n\n\n\n\nTo keep things simple and accessible on a Colab with free resources (the T4 GPU), we will use the canonical MNIST dataset of handwritten digits, 0-9.\nOur training loop will run for five epochs and should complete within a few minutes on the T4.\n\n# Load and preprocess the MNIST dataset\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\ntrain_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):  # 5 epochs for demonstration\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = model(data.view(data.size(0), -1))\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n    if (epoch + 1) % 1 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\nEpoch [1/5], Loss: 0.0020\nEpoch [2/5], Loss: 0.0002\nEpoch [3/5], Loss: 0.0047\nEpoch [4/5], Loss: 0.0026\nEpoch [5/5], Loss: 0.0004\n\n\n\n2.0.1 Visualizing Weight Matrices\nOne way to observe superposition is by visualizing the weight matrices of our layers. We can plot these as heatmaps:\nIn these heatmaps, look for:\n\nPatterns or structure in the weights\nAreas of high positive or negative values\nRegions where weights seem to cancel each other out\n\nGenerally, we see the first layer has sparse weights. This is because it connects directly to input pixels, many of which are not useful for making predictions, for example, the white space. The network will learn to assign very low weights to these less informative pixels.\nIn the second layer, we see a denser heatmap. Since this layer receives input from the first layer’s activations, these features are likely to be meaningful and more evenly distributed for digit recognition. This leads to a denser weight matrix, since the layer is using more of its inputs.\n\n\n2.0.2 Relation to Superposition\nEven the sparsity in the first layer may hide some degree of superposition, since the non-zero weights may be encoding multiple features in a superimposed manner. This is especially likely since the first layer ends up with fewer neurons than input dimensions.\nReminding ourselves of the architecture:\n(fc1): Linear(in_features=784, out_features=128, bias=True)\nThis means that the input features map to the 784 pixels of the MNIST images inputs, however its out_features reduces the dimensionality to 128.\nIn the second layer, where low-level features are combined into more abstract representations, superposition is noticeable as many patterns are encoded efficiently in a limited number of neurons.\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plot_weight_matrix(weight_matrix, title):\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(weight_matrix.cpu().detach().numpy(), cmap='coolwarm', center=0)\n    plt.title(title)\n    plt.show()\n\nplot_weight_matrix(model.fc1.weight, \"First Layer Weights\")\nplot_weight_matrix(model.fc2.weight, \"Second Layer Weights\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.0.3 Analyzing Activations\nAnother approach is to analyze the activations of neurons in response to different inputs:\n\ndef get_activations(model, input_data):\n    activations = {}\n\n    def hook_fn(module, input, output):\n        activations[module] = output.detach()\n\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Linear):\n            module.register_forward_hook(hook_fn)\n    input_data = input_data.to(device)\n    model(input_data)\n    return activations\n\n# Get a batch of test data\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST(root='./data', train=False, transform=transform),\n    batch_size=64, shuffle=True)\ntest_data, _ = next(iter(test_loader))\n\nactivations = get_activations(model, test_data.view(test_data.size(0), -1))\n\n# Plot activation distributions\nfor name, activation in activations.items():\n    plt.figure(figsize=(10, 6))\n    plt.hist(activation.cpu().numpy().flatten(), bins=50)\n    plt.title(f\"Activation Distribution for {name}\")\n    plt.xlabel(\"Activation Value\")\n    plt.ylabel(\"Frequency\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.0.4 Measuring Superposition\nTo quantify superposition, we can use techniques like Singular Value Decomposition (SVD) on the weight matrices.\nSVD is a technique in linear algebra to distill matrices into simpler component matrices.\nIn this example, we take the following steps (also commented in the code):\n\nCompute total variance, which is the sum of squared singular values\nCalculate the cumulative variance of each singular value\n\n\n2.0.4.1 Interpretation\nThe ‘effective rank’ is a measure of superposition. A lower effective rank indicated less of the phenonemon. A higher effective rank suggests more, implying the weight matrix requires more dimensions to be accurately represented.\n\nimport numpy as np\n\ndef analyze_superposition(weight_matrix):\n    # Here's the SVD calculation. The 'S' array contains the\n    # singular values in descending order.\n    U, S, Vt = np.linalg.svd(weight_matrix.cpu().detach().numpy())\n\n    # Plot singular values\n    plt.figure(figsize=(10, 6))\n    plt.plot(S)\n    plt.title(\"Singular Values of Weight Matrix\")\n    plt.xlabel(\"Index\")\n    plt.ylabel(\"Singular Value\")\n    plt.yscale('log')\n    plt.show()\n\n    # Calculate 'effective rank', which is a measure of superposition.\n    # This computes the total variance (sum of squared values), then\n    # calculates the cumulative variance explained by each singular value.\n    total_variance = np.sum(S**2)\n    cumulative_variance = np.cumsum(S**2) / total_variance\n    effective_rank = np.sum(cumulative_variance &lt; 0.99)  # 99% of variance\n\n    print(f\"Effective Rank: {effective_rank}\")\n\nanalyze_superposition(model.fc1.weight)\nanalyze_superposition(model.fc2.weight)\n\n\n\n\n\n\n\n\nEffective Rank: 110\n\n\n\n\n\n\n\n\n\nEffective Rank: 54\n\n\nIn our SimpleNet model, we defined the following architecture:\n\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(784, 128)\n        self.fc2 = nn.Linear(128, 64)\n        self.fc3 = nn.Linear(64, 10)\nLet’s compare the effective ranks we observed with the actual number of neurons in each layer:\nFirst layer (fc1):\nTotal neurons: 128 Effective rank: 113 Ratio: 113 / 128 ≈ 0.883 or 88.3%\nSecond layer (fc2):\nTotal neurons: 64 Effective rank: 54 Ratio: 54 / 64 ≈ 0.844 or 84.4%\nInterpretation:\nFirst layer (fc1): The effective rank of 113 compared to 128 total neurons suggests that this layer is using about 88.3% of its capacity for unique features, corresponding to a high degree of superposition. So a large number of singular values are needed to explain the variance in the weight matricies.\nSecond layer (fc2): The effective rank of 54 vs 64 total neurons indicates that this layer is using about 84.4% of its capacity for unique features, showing a slight decrease that may indicate more specialization or feature abstraction in the second layer.\nThe effective rank gives us an idea of how many “effective features” the layer is representing. A higher effective rank compared to the actual number of neurons suggests neurons are representing multiple features simultaneously, indicating a higher degree of superposition.\n\n\n\n2.0.5 Interpreting the Results\nWhen looking at the results, focus on sparse activation patterns, which might indicate specialized neurons. Compare the number of neurons to the effective rank - a large discrepancy suggests a high degree of superposition. Observe how superposition changes across layers. Consider how different input patterns affect the activations and whether this reveals any superposed features.\n\n\n2.0.6 More layers, more data: CIFAR 100\nLet’s explore whether larger datasets and more complex neural network architectures affect the degree of superposition.\nWe switch to the ResNet50 model, which has 50 layers, including 48 convolutional layers, 1 max pool and 1 average pool layer. It uses skip connections to address the vanishing gradient problem, enabling training of deeper networks.\nWe will use the CIFAR-100 dataset, which comprises 60,000, 32 x 32 color images in 100 classes.\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, datasets, transforms\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom tqdm import tqdm\n\n# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Define transforms\ntransform_train = transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n])\n\n# Load CIFAR-100 dataset\ntrain_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\ntest_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n\n# Load pre-trained ResNet50 model and modify for CIFAR-100\nmodel = models.resnet50(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 100)  # 100 classes in CIFAR-100\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1} loss: {running_loss/len(train_loader):.4f}\")\n\n    # Validation\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in tqdm(test_loader, desc=\"Validation\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n\n    print(f\"Validation Accuracy: {100.*correct/total:.2f}%\")\n\nprint(\"Training completed\")\n\n\nUsing device: cuda\nDownloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n\n\n100%|██████████| 169001437/169001437 [00:04&lt;00:00, 42237449.26it/s]\n\n\nExtracting ./data/cifar-100-python.tar.gz to ./data\nFiles already downloaded and verified\n\n\n/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00&lt;00:00, 130MB/s]\nEpoch 1/10: 100%|██████████| 391/391 [00:34&lt;00:00, 11.18it/s]\n\n\nEpoch 1 loss: 3.3070\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 24.33it/s]\n\n\nValidation Accuracy: 25.89%\n\n\nEpoch 2/10: 100%|██████████| 391/391 [00:33&lt;00:00, 11.58it/s]\n\n\nEpoch 2 loss: 2.5782\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 19.93it/s]\n\n\nValidation Accuracy: 41.69%\n\n\nEpoch 3/10: 100%|██████████| 391/391 [00:34&lt;00:00, 11.28it/s]\n\n\nEpoch 3 loss: 2.1787\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 23.63it/s]\n\n\nValidation Accuracy: 45.72%\n\n\nEpoch 4/10: 100%|██████████| 391/391 [00:33&lt;00:00, 11.62it/s]\n\n\nEpoch 4 loss: 2.0079\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 25.49it/s]\n\n\nValidation Accuracy: 48.87%\n\n\nEpoch 5/10: 100%|██████████| 391/391 [00:33&lt;00:00, 11.72it/s]\n\n\nEpoch 5 loss: 1.7884\n\n\nValidation: 100%|██████████| 79/79 [00:05&lt;00:00, 15.58it/s]\n\n\nValidation Accuracy: 50.87%\n\n\nEpoch 6/10: 100%|██████████| 391/391 [00:33&lt;00:00, 11.65it/s]\n\n\nEpoch 6 loss: 1.6728\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 25.56it/s]\n\n\nValidation Accuracy: 51.85%\n\n\nEpoch 7/10: 100%|██████████| 391/391 [00:33&lt;00:00, 11.60it/s]\n\n\nEpoch 7 loss: 1.5569\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 25.69it/s]\n\n\nValidation Accuracy: 53.72%\n\n\nEpoch 8/10: 100%|██████████| 391/391 [00:34&lt;00:00, 11.41it/s]\n\n\nEpoch 8 loss: 1.4626\n\n\nValidation: 100%|██████████| 79/79 [00:04&lt;00:00, 15.99it/s]\n\n\nValidation Accuracy: 53.80%\n\n\nEpoch 9/10: 100%|██████████| 391/391 [00:34&lt;00:00, 11.32it/s]\n\n\nEpoch 9 loss: 1.4110\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 24.77it/s]\n\n\nValidation Accuracy: 54.18%\n\n\nEpoch 10/10: 100%|██████████| 391/391 [00:33&lt;00:00, 11.73it/s]\n\n\nEpoch 10 loss: 1.3250\n\n\nValidation: 100%|██████████| 79/79 [00:03&lt;00:00, 24.64it/s]\n\n\nValidation Accuracy: 55.82%\nTraining completed\n\n\n\n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import OrderedDict\n\ndef get_activations(model, loader, num_batches=10):\n    activations = OrderedDict()\n\n    def hook_fn(name):\n        def hook(module, input, output):\n            activations[name] = output.cpu().detach()\n        return hook\n\n    # Register hooks for convolutional layers\n    for name, module in model.named_modules():\n        if isinstance(module, nn.Conv2d):\n            module.register_forward_hook(hook_fn(name))\n\n    model.eval()\n    with torch.no_grad():\n        for i, (inputs, _) in enumerate(loader):\n            if i &gt;= num_batches:\n                break\n            inputs = inputs.to(device)\n            _ = model(inputs)\n\n    return activations\n\ndef analyze_superposition(activation, layer_name):\n    reshaped = activation.reshape(activation.shape[1], -1).numpy()\n    U, S, Vt = np.linalg.svd(reshaped, full_matrices=False)\n\n    total_variance = np.sum(S**2)\n    cumulative_variance = np.cumsum(S**2) / total_variance\n    effective_rank = np.sum(cumulative_variance &lt; 0.99)  # 99% of variance\n\n    return {\n        'layer_name': layer_name,\n        'total_channels': activation.shape[1],\n        'effective_rank': effective_rank,\n        'ratio': effective_rank / activation.shape[1]\n    }\n\n# Get activations\nactivations = get_activations(model, test_loader)\n\n# Analyze superposition for each layer\nresults = []\nfor name, activation in activations.items():\n    results.append(analyze_superposition(activation, name))\n\n# Create DataFrame\ndf = pd.DataFrame(results)\n\n# Plot effective rank vs layer\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x=df.index, y='effective_rank', marker='o')\nplt.title('Effective Rank vs Layer')\nplt.xlabel('Layer Index')\nplt.ylabel('Effective Rank')\nplt.xticks(df.index, df['layer_name'], rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('effective_rank_vs_layer.png')\nplt.close()\n\n# Plot ratio of effective rank to total channels\nplt.figure(figsize=(12, 6))\nsns.lineplot(data=df, x=df.index, y='ratio', marker='o')\nplt.title('Ratio of Effective Rank to Total Channels vs Layer')\nplt.xlabel('Layer Index')\nplt.ylabel('Ratio')\nplt.xticks(df.index, df['layer_name'], rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('effective_rank_ratio_vs_layer.png')\nplt.close()\n\nprint(df)\nprint(\"\\nAnalysis completed. Check the generated PNG files for visualizations.\")\n\n               layer_name  total_channels  effective_rank     ratio\n0                   conv1              64              59  0.921875\n1          layer1.0.conv1              64              49  0.765625\n2          layer1.0.conv2              64              53  0.828125\n3          layer1.0.conv3             256             139  0.542969\n4   layer1.0.downsample.0             256             133  0.519531\n5          layer1.1.conv1              64              59  0.921875\n6          layer1.1.conv2              64              58  0.906250\n7          layer1.1.conv3             256             202  0.789062\n8          layer1.2.conv1              64              60  0.937500\n9          layer1.2.conv2              64              60  0.937500\n10         layer1.2.conv3             256             231  0.902344\n11         layer2.0.conv1             128             112  0.875000\n12         layer2.0.conv2             128             113  0.882812\n13         layer2.0.conv3             512             419  0.818359\n14  layer2.0.downsample.0             512             398  0.777344\n15         layer2.1.conv1             128              99  0.773438\n16         layer2.1.conv2             128              52  0.406250\n17         layer2.1.conv3             512             229  0.447266\n18         layer2.2.conv1             128             108  0.843750\n19         layer2.2.conv2             128              87  0.679688\n20         layer2.2.conv3             512             360  0.703125\n21         layer2.3.conv1             128             110  0.859375\n22         layer2.3.conv2             128              86  0.671875\n23         layer2.3.conv3             512             372  0.726562\n24         layer3.0.conv1             256             220  0.859375\n25         layer3.0.conv2             256             169  0.660156\n26         layer3.0.conv3            1024             344  0.335938\n27  layer3.0.downsample.0            1024             385  0.375977\n28         layer3.1.conv1             256             117  0.457031\n29         layer3.1.conv2             256              50  0.195312\n30         layer3.1.conv3            1024              78  0.076172\n31         layer3.2.conv1             256             121  0.472656\n32         layer3.2.conv2             256              44  0.171875\n33         layer3.2.conv3            1024              83  0.081055\n34         layer3.3.conv1             256             126  0.492188\n35         layer3.3.conv2             256              41  0.160156\n36         layer3.3.conv3            1024              25  0.024414\n37         layer3.4.conv1             256             116  0.453125\n38         layer3.4.conv2             256              26  0.101562\n39         layer3.4.conv3            1024              25  0.024414\n40         layer3.5.conv1             256             116  0.453125\n41         layer3.5.conv2             256              32  0.125000\n42         layer3.5.conv3            1024              29  0.028320\n43         layer4.0.conv1             512             235  0.458984\n44         layer4.0.conv2             512             100  0.195312\n45         layer4.0.conv3            2048             121  0.059082\n46  layer4.0.downsample.0            2048             116  0.056641\n47         layer4.1.conv1             512              70  0.136719\n48         layer4.1.conv2             512              46  0.089844\n49         layer4.1.conv3            2048              43  0.020996\n50         layer4.2.conv1             512              62  0.121094\n51         layer4.2.conv2             512              58  0.113281\n52         layer4.2.conv3            2048              27  0.013184\n\nAnalysis completed. Check the generated PNG files for visualizations.\n\n\n\n\n2.0.7 Interpretation\nWith some consistency, we see effective rank ratio decrease as the later network layers learn more abstract representations.\n\n# Display the image in the notebook\nimage_path = \"/content/effective_rank_ratio_vs_layer.png\"\ndisplay(Image(filename=image_path))\n\n\n\n\n\n\n\n\n\n\n3 Interpreting Superposition Analysis Results\nLet’s analyze a result for one single convolutional layer\nConv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False):\nTotal channels: 512\nEffective Rank: 67\nRatio: 0.13\n\nLayer description: Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n\nThis is a 2D convolutional layer\nIt takes 2048 input channels and outputs 512 channels\nIt uses a 1x1 kernel size, which is essentially a pointwise convolution\n\nTotal channels: 512\n\nIn a convolutional neural network, each channel can be thought of as a “neuron” or a feature detector\nSo this layer has 512 “neurons” or feature detectors\n\nEffective Rank: 67\n\nThis is significantly lower than the number of channels (512), indicating a small subset of the available dimensions are needed to explain most of the variance in the weight matrix. This suggests low superposition, since the majority of channels are not contributing to complex representations.\n\nRatio: 0.13 (67 / 512)\n\nThis ratio indicates that only about 13% of the available dimensions are being effectively utilized\n\n\nIn summary, this result shows a lower degree of superposition, with the layer using only about 67 effective dimensions to represent information, despite having 512 channels available.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Initial explorations</span>"
    ]
  },
  {
    "objectID": "language_models.html",
    "href": "language_models.html",
    "title": "3  Superposition in language models",
    "section": "",
    "text": "In this section, we will explore how language models encode a variety of concepts in the same sets of neurons.\nLet’s start with a simple language model. We can use a correlation matrix to see a heatmap of activations for each hidden neuron in the input sequence.\n\n!pip install transformers datasets torchviz\n\n\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\n# Set random seed for reproducibility\ntorch.manual_seed(42)\n\n# Define a simple language model\nclass SimpleLanguageModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.linear = nn.Linear(embedding_dim, hidden_dim)\n        self.output = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        x = torch.relu(self.linear(x))\n        return self.output(x)\n\n# Parameters\nvocab_size = 1000\nembedding_dim = 50\nhidden_dim = 20\nnum_concepts = 5\n\n# Create model\nmodel = SimpleLanguageModel(vocab_size, embedding_dim, hidden_dim)\n\n# Generate random input\ninput_ids = torch.randint(0, vocab_size, (100,))\n\n# Get hidden layer activations\nwith torch.no_grad():\n    embeddings = model.embedding(input_ids)\n    hidden_activations = torch.relu(model.linear(embeddings))\n\n# Simulate concept activations\nconcept_activations = torch.rand((num_concepts, hidden_dim))\n\n# Visualize superposition\nplt.figure(figsize=(12, 6))\n\n# Plot hidden neuron activations\nplt.subplot(1, 2, 1)\nplt.imshow(hidden_activations.T, aspect='auto', cmap='viridis')\nplt.title('Hidden Neuron Activations')\nplt.xlabel('Sequence Position')\nplt.ylabel('Hidden Neuron')\n\n# Plot concept activations\nplt.subplot(1, 2, 2)\nplt.imshow(concept_activations, aspect='auto', cmap='viridis')\nplt.title('Concept Activations')\nplt.xlabel('Hidden Neuron')\nplt.ylabel('Concept')\n\nplt.tight_layout()\nplt.show()\n\n# Print correlation matrix\ncorrelation_matrix = torch.corrcoef(torch.cat([hidden_activations.mean(dim=0).unsqueeze(0), concept_activations]))\nprint(\"Correlation Matrix:\")\nprint(correlation_matrix)\n\n\n\n\n\n\n\n\nCorrelation Matrix:\ntensor([[ 1.0000,  0.2627, -0.0627,  0.0544,  0.1577, -0.2853],\n        [ 0.2627,  1.0000,  0.0604, -0.0051,  0.5944,  0.3043],\n        [-0.0627,  0.0604,  1.0000,  0.0394,  0.1046, -0.1701],\n        [ 0.0544, -0.0051,  0.0394,  1.0000, -0.2142,  0.0359],\n        [ 0.1577,  0.5944,  0.1046, -0.2142,  1.0000, -0.1420],\n        [-0.2853,  0.3043, -0.1701,  0.0359, -0.1420,  1.0000]])\n\n\n\n3.0.1 Interpretation\nIn these visualizations, we see multiple concepts encoded in the same set of neurons.\nIn the first (left) subplot, we a heatmap of activations for each hidden neuron in the input sequence.\n\nEach row represents a single neuron in the hidden layer\nEach column represents a position in the input sequence\nThe color intensity indicates the activation strength of each neuron at each position, with brighter colors showing higher activation\n\nIn the second, concept activations visualization, we see a heatmap showing activation patterns for different concepts across the hidden neurons.\n\nRows represent different concepts\nColumns represent neurons in the hidden layer\nColor intensity indicates how strongly each concept is associated with each hidden neuron\nBrighter colors indicate stronger activations\n\n\n\n3.0.2 The key idea\nThese two visualizations overlap in hidden neuron space, so the same set of neurons are encoding both sequence and concept information simultaneously. That these two aspects coexist in the same hidden layer demonstrates superposition.\n\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom datasets import load_dataset\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n\n# Check if CUDA is available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load pre-trained model and tokenizer\nmodel_name = \"distilbert-base-uncased\"\ntokenizer = DistilBertTokenizer.from_pretrained(model_name)\nmodel = DistilBertModel.from_pretrained(model_name).to(device)\n\n# Load a subset of the GLUE dataset (SST-2 for sentiment analysis)\ndataset = load_dataset(\"glue\", \"sst2\", split=\"train[:1000]\")\n\n# Tokenize the dataset\ndef tokenize_function(examples):\n    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=dataset.column_names)\ntokenized_dataset.set_format(\"torch\")\n\n# Define linguistic concepts (simple version)\nconcepts = {\n    \"positive\": [\"good\", \"great\", \"excellent\", \"wonderful\", \"fantastic\"],\n    \"negative\": [\"bad\", \"terrible\", \"awful\", \"horrible\", \"poor\"],\n    \"neutral\": [\"okay\", \"fine\", \"average\", \"mediocre\", \"so-so\"]\n}\n\n# Function to get hidden states\ndef get_hidden_states(batch):\n    inputs = {k: v.to(device) for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n    with torch.no_grad():\n        outputs = model(**inputs)\n    return outputs.last_hidden_state.cpu().numpy()\n\n# Get hidden states for the dataset\nhidden_states = []\nfor i in range(0, len(tokenized_dataset), 32):\n    batch = tokenized_dataset[i:i+32]\n    hidden_states.append(get_hidden_states(batch))\n\nhidden_states = np.concatenate(hidden_states, axis=0)\n\n# Calculate average hidden state for each input\navg_hidden_states = np.mean(hidden_states, axis=1)\n\n# Perform PCA\npca = PCA(n_components=2)\nreduced_states = pca.fit_transform(avg_hidden_states)\n\n# Visualize the reduced hidden states\nplt.figure(figsize=(12, 8))\nscatter = plt.scatter(reduced_states[:, 0], reduced_states[:, 1], c=dataset[\"label\"], cmap=\"coolwarm\", alpha=0.6)\nplt.colorbar(scatter)\nplt.title(\"PCA of Average Hidden States Colored by Sentiment\")\nplt.xlabel(\"First Principal Component\")\nplt.ylabel(\"Second Principal Component\")\nplt.show()\n\n# Function to get concept embeddings\ndef get_concept_embeddings(concepts):\n    concept_embeddings = {}\n    for concept, words in concepts.items():\n        embeddings = []\n        for word in words:\n            inputs = tokenizer(word, return_tensors=\"pt\").to(device)\n            with torch.no_grad():\n                outputs = model(**inputs)\n            embeddings.append(outputs.last_hidden_state.mean(dim=1).cpu().numpy())\n        concept_embeddings[concept] = np.mean(embeddings, axis=0).flatten()\n    return concept_embeddings\n\nconcept_embeddings = get_concept_embeddings(concepts)\n\n# Calculate correlation between average hidden states and concept embeddings\ncorrelations = {}\nfor concept, embedding in concept_embeddings.items():\n    corr = np.mean([np.corrcoef(avg_state, embedding)[0, 1] for avg_state in avg_hidden_states])\n    correlations[concept] = corr\n\n# Visualize correlations\nplt.figure(figsize=(10, 6))\nsns.barplot(x=list(correlations.keys()), y=list(correlations.values()))\nplt.title(\"Average Correlation between Hidden States and Concept Embeddings\")\nplt.ylabel(\"Correlation\")\nplt.show()\n\nprint(\"Correlations:\", correlations)\n\nUsing device: cuda\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCorrelations: {'positive': 0.33541225356469684, 'negative': 0.3389937145819827, 'neutral': 0.37208967616205857}\n\n\n\n\n3.0.3 Interpretation\nIn the PCA plot, we see clusters of points with different colors, suggesting the model is distinguishing between different sentiments in its hidden representations.\nIn the correlation bar plot, the higher values suggest hidden states are more tightly correlated with that particular concept. The high correlations for multiple concepts suggests the model is encoding multiple concepts simultaneously in its hidden states.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Superposition in language models</span>"
    ]
  },
  {
    "objectID": "sparse_autoencoders.html",
    "href": "sparse_autoencoders.html",
    "title": "4  Interpreting with Sparse Autoencoders",
    "section": "",
    "text": "!pip install torch transformers\n\nIn this notebook, we will explore one of the cutting-edge approaches to interpreting superposition: sparse autoencoders (SAE).\nSAEs are a type of neural network used in unsupervised learning and feature extraction. Autoencoders are generally useful for detecting patterns that are difficult for humans to discern. SAEs have the following characteristics:\n\nAn encoder to compress data and a decoder to recontruct it\nThe SAE enforces sparsity in the hidden layer, activating a small number of neurons for a given input\nThis sparsity forces the network to learn more efficient and meaningful representations of the input data\nTrained to minimize reconstruction error\nUseful for feature learning, dimensionality reduction, data denoising\n\nLet’s import GPT-2 for examination and set up a simple SAE.\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom transformers import GPT2LMHeadModel, GPT2Tokenizer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set up device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load pre-trained GPT-2 model\nmodel_name = 'gpt2'\ntokenizer = GPT2Tokenizer.from_pretrained(model_name)\ngpt2_model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n\n# Define Sparse Autoencoder\nclass SparseAutoencoder(nn.Module):\n    def __init__(self, input_dim, hidden_dim):\n        super(SparseAutoencoder, self).__init__()\n        self.encoder = nn.Linear(input_dim, hidden_dim)\n        self.decoder = nn.Linear(hidden_dim, input_dim)\n\n    def forward(self, x):\n        encoded = torch.relu(self.encoder(x))\n        decoded = self.decoder(encoded)\n        return encoded, decoded\n\n\n/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe following function enables the extraction of activations from GPT-2. The function is liberally commented to explain how to keep track of activations.\nHere’s how it works: * Tokenize the text * Ensure output is a PyTorch tensor * Return hidden states (activations) from all layers * output_hidden_states is a tuple containing the hidden states from all layers by layer_idx, which allows us to choose which layer’s activations are of interest.\n\n# Function to get GPT-2 activations\ndef get_gpt2_activations(text, layer_idx=-1):\n    # Tokenize input text; ensure output is a PyTorch (\".pt\") tensor\n    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n    # Model inference, without tracking gradients. This saves memory,\n    # since we are only interested in inference, not training\n    with torch.no_grad():\n        # The output_hidden_states method returns the hidden states,\n        # aka activations, from all layers, not just the final output\n        outputs = gpt2_model(**inputs, output_hidden_states=True)\n    # outputs.hidden_states is a tuple containing hidden states from\n    # all layers of the model. squeeze() removes extra dimensions\n    # of size 1 from the tensor.\n    return outputs.hidden_states[layer_idx].squeeze()\n\n\ndef train_sparse_autoencoder(autoencoder, activations, num_epochs=500, sparsity_weight=0.01):\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n\n    for epoch in range(num_epochs):\n        optimizer.zero_grad()\n        encoded, decoded = autoencoder(activations)\n\n        recon_loss = criterion(decoded, activations)\n        sparsity_loss = torch.mean(torch.abs(encoded))\n        loss = recon_loss + sparsity_weight * sparsity_loss\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        if (epoch + 1) % 100 == 0:\n            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n    return autoencoder\n\nThe following visualizations should help explain the findings of the sparse autoencoder. One will show the strength of the activations, the other, learned feature importance.\n\ndef visualize_features(autoencoder, num_features, save_path='learned_features.png'):\n    weights = autoencoder.encoder.weight.data.cpu().numpy()\n    fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n    for i in range(num_features):\n        ax = axes[i // 4, i % 4]\n        sns.heatmap(weights[i].reshape(1, -1), ax=ax, cmap='viridis', cbar=False)\n        ax.set_title(f'Feature {i+1}')\n        ax.axis('off')\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n\ndef visualize_activation_strengths(encoded, num_features, save_path='activation_strengths.png'):\n    plt.figure(figsize=(12, 6))\n    plt.bar(range(num_features), encoded[:num_features])\n    plt.title('Activation Strengths of Learned Features')\n    plt.xlabel('Feature Index')\n    plt.ylabel('Activation Strength')\n    plt.xticks(range(0, num_features, 2))  # Label every other feature for readability\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n\ndef analyze_superposition(text, hidden_dim=16):\n    # Get GPT-2 activations\n    activations = get_gpt2_activations(text).to(device)\n    input_dim = activations.shape[-1]\n\n    # Initialize and train sparse autoencoder\n    autoencoder = SparseAutoencoder(input_dim, hidden_dim).to(device)\n    trained_autoencoder = train_sparse_autoencoder(autoencoder, activations)\n\n    # Visualize learned features\n    visualize_features(trained_autoencoder, hidden_dim)\n\n    # Analyze activations\n    encoded, _ = trained_autoencoder(activations)\n    encoded = encoded.mean(dim=0).squeeze().cpu().detach().numpy()\n\n    # Plot activation strengths\n    visualize_activation_strengths(encoded, hidden_dim)\n\n    print(f\"Analysis complete. Check 'learned_features.png' and 'activation_strengths.png' for visualizations of {hidden_dim} features.\")\n\n# Run the analysis with multiple inputs\ntexts = [\n    \"It was the best of times, it was the worst of times.\",\n    # \"To be or not to be, that is the question.\",\n    # \"In a hole in the ground there lived a hobbit.\",\n    # \"It was the best of times, it was the worst of times.\"\n]\n\nfor i, text in enumerate(texts):\n    print(f\"\\nAnalyzing text {i+1}: '{text}'\")\n    analyze_superposition(text, hidden_dim=16)\n\n\nAnalyzing text 1: 'It was the best of times, it was the worst of times.'\nEpoch [100/500], Loss: 10.9564\nEpoch [200/500], Loss: 2.0957\nEpoch [300/500], Loss: 1.4265\nEpoch [400/500], Loss: 1.3351\nEpoch [500/500], Loss: 1.3095\nAnalysis complete. Check 'learned_features.png' and 'activation_strengths.png' for visualizations of 16 features.\n\n\n\n4.0.1 Learned feature importance\nWhat do we mean by ‘features’ in this example?\nModels such as GPT-2 create a distributed representation of words and concepts. Information about a single word is spread across many dimensions of the model’s internal representations, and each dimension contributes to the representation of many different words or concepts.\nGPT-2, like many transformer models, uses contextual embeddings, so the representation of a word will change based on its context, eg the word ‘bark’ in sentences such as ‘A dog’s bark’ and ‘The bark on the tree’ will have different activations.\nThe sparse autoeocnder is trying to find efficient ways to encode the patterns in the activations, rather than to isolate individual words.\n\nfrom IPython.display import Image, display\n\n# Display the image in the notebook\nimage_path = \"learned_features.png\"\ndisplay(Image(filename=image_path))\n\n\n\n\n\n\n\n\n\n\n4.0.2 Activation strengths\nIn this visualization, high activations for some features suggest those features are particularly relevant to representing the input sentence. The pattern of activations across all features shows how the model is representing the entire input.\nEach bar respresents one of the features learned by the SAE, and the height indicates how strongly the feature was activated for the input text.\nLook for sparsity: a successful sparse representation will have many features with low activation (shorter bars), only a few will have high activations (tall bars). The overall distribution can give clues about how the autoencoder is representing the information.\nIn the GPT-2 model, the input text is distributed across all dimensions of its activation vector, so the SAE tries to represent the same information with fewer specific features.\n\nfrom IPython.display import Image, display\n\n# Display the image in the notebook\nimage_path = \"activation_strengths.png\"\ndisplay(Image(filename=image_path))\n\n\n\n\n\n\n\n\nIn considering these two visualizations together, try to correlate the strong activations in the activation strengths with feature patterns in the heatmap.\nLook for groups of features that seem to have similar patterns in the heatmap or similar activation levels, which many indicate related aspects of language that GPT-2 represents.\n\n\n4.0.3 Summary\nThis example has shown how in the learned_features heatmap how information comprising different linguistic contexts (syntax, semantics etc) is superposed across the same set of neurons in the original model.\nIn the activation_strengths plot, we see how these disentangled features are used to respresent a specific input, with varying levels of activation indicating extracted feature relevance.\nThe activation of multiple features simultaneously shows how GPT-2 superposes different pieces of information in its dense representation, which the SAE has decomposed into more interpretable units.|",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Interpreting with Sparse Autoencoders</span>"
    ]
  },
  {
    "objectID": "for_policy_specialists.html",
    "href": "for_policy_specialists.html",
    "title": "5  Superposition for Policy Specialists",
    "section": "",
    "text": "5.0.1 What is superposition?\nSuperposition in neural networks concerns how these systems efficiently represent and process multiple concepts or features within the same set of neurons or parameters. Unlike traditional computer programs where every piece of information typically has a specific address in memory, neural nets distribute this information across their entire architecture. Information and its storage overlaps, and this helps the network learn in greater depth from its inputs.\nThis feature allows neural nets to be efficieint in their use of the computational resources they employ to help them understand input data. The networks can understand input information with far more numerous inputs than there are neurons to make sense of them.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superposition for Policy Specialists</span>"
    ]
  },
  {
    "objectID": "for_policy_specialists.html#avenues-to-improve-interpretability",
    "href": "for_policy_specialists.html#avenues-to-improve-interpretability",
    "title": "5  Superposition for Policy Specialists",
    "section": "5.1 Avenues to improve interpretability",
    "text": "5.1 Avenues to improve interpretability\n\n5.1.1 Visualization\nWe have convered some techniques in this course to apply visualizations to detect and understand superposition.\n\n\n5.1.2 Proving and ablation\nTechniques to isolate specific or groups of neurons to understand behaviour. For excellent examples, see Anthropic’s work: * Towards Monosemanticity * and visualization\n\n\n5.1.3 Disentanglement\nResearch focused on training networks to encourage more separated, interpretable representations. Please see Disentangled Explanations of Neural Network Predictions.\n\n\n5.1.4 Formal theories of representation\nUsing mathematical frameworks to decribe how information is encoded and processed could improve understanding.\n\n\n5.1.5 Explainable AI\nDeveloping tools to explain how neural nets are making decisions.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superposition for Policy Specialists</span>"
    ]
  },
  {
    "objectID": "for_policy_specialists.html#conclusion",
    "href": "for_policy_specialists.html#conclusion",
    "title": "5  Superposition for Policy Specialists",
    "section": "5.2 Conclusion",
    "text": "5.2 Conclusion\nSuperposition is a fundamental characteristic that affords neural nets the power and complexity to make predictions and generations based on often voluminous input data. For policy specialists, understanding this charactersitic of AI systems helps inform the development of governance strategies to mitigate ethical and societal impact concerns of non-deterministic systems.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Superposition for Policy Specialists</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Unravelling Superposition",
    "section": "",
    "text": "Preface\nWelcome to the course!\nIn the nascent field of AI Safety and Alignment, superposition is a key topic illustrative of the elusive nature of neural networks and how and what they learn, and how we can develop techniques to achieve greater insight.\nThe following notebooks will explain the concept and introduce you to some of the technical approches in PyTorch we can use to conduct practical research in the field.\nIf you are a technical practitioner and familiar with Python and PyTorch, the code notebooks highlighting the concept start at ‘Introduction to Superposition’.\nFor policy specialists, please have a look at the ‘Superposition for Policy Specialists’ section.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "6  Summary",
    "section": "",
    "text": "6.1 References",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "summary.html#references",
    "href": "summary.html#references",
    "title": "6  Summary",
    "section": "",
    "text": "Toy models of superposition by Nelson Elhage, Tristan Hume and Catherine Olsson et al. (2022)\nTowards Monosemanticity: Decomposing Language Models With Dictionary Learning by Trenton Bricken, Adly Templeton and Joshua Batson et al. (2023)\nPolysemanticity and Capacity in Neural Networks by Adam Scherlis, Kshitij Sachan, Adam S. Jermyn, Joe Benton and Buck Shlegeris",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Summary</span>"
    ]
  }
]